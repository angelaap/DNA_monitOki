---
title: "RINKO"
author: "Ares, A."
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  word_document:
    toc: yes
    toc_depth: '5'
  pdf_document:
    toc: yes
    toc_depth: '5'
  html_document:
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_depth: 5
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This document describes the procedures for data cleaning and wrangling of data collected with RINKO logger during the DNA monitoring project. RINKO is a profiler use to collect physicochemical parameters of sea and freshwater including depth, temperature, chlorophyll, conductivity, salinity, DO and turbidity. 

## Remove outliers
Usually, first seconds of collection are very unstable so we need to remove them in order to continue with the analysis. 
There is one .csv file per day and site of sampling. 
I will use Ayse's code for this part.

```{r packages}
#load packages
library(dplyr)
library(tibble)
library(readxl)
library(matrixStats)
#library(xlsx) problem with JAVA, so I will try openxlsx package
library(openxlsx)
library(purrr)
library(stringr)
```

The name of the columns need to be re-defined
```{r colnames}
# original column names
cols_eng <- c("Date", "Location", "Time", "Depth (m)", "Water temperature (?C)", 
              "Salinity", "Conductivity (mS/cm)", 
              "EC25 (??S/cm)", "Density (kg/m^3)", "??T", 
              "Chl-Flu (ppb)", "Chl-a (??g/l)", "Turbidity range (FTU)",
              "DO (%)", "Weiss-DO (mg/l)", "Voltage (V)", 
              "G&G-DO (mg/l)", "B&K-DO (mg/l)")  

# the desired columns' names
# id: the name of the file the data came from.
vars <- c("id", "date", "location", "sample", "time", 
          "depth", "water_temp", 
          "salinity", "conductivity", 
          "ec25", "density", "sT", 
          "chl_f", "chl_a", "tur_range",
          "do", "weiss_do", "v", 
          "gg_do", "bk_do") 

print(vars[c(2, 5, 6:20)])

```

When using Rinko, data tend to be unstable the first seconds of the measurement, therefore we need to define a function to remove the outliers at the beginning of this measurement. 
```{r remove outliers}

remove_outliers_column <- function (a) {
  b <- as.matrix(a)
  qnt <- colQuantiles(b, probs=c(.25, .75), na.rm = TRUE)
  # print(qnt)
  H <- 1.5 * IQR(b, na.rm = TRUE)
  # print(H)
  low <- qnt[1] - H
  up <- qnt[2] + H
  
  b[a < low] <- NA
  b[a > up] <- NA
  
  b <- as.data.frame(b)
  b 
}
```

Check all the files included in the 26 folders (each for each sampling day). In each of the folders there are 12 files (format .csv) each for each sampled site
```{r}
rinko_folder <- "~/Documents/GitHub/DNA_monitOki/Environmental parameters/Rinko data python mining/"
rinko_csv_files <- 
  list.files(path = rinko_folder, recursive= TRUE, pattern = "*.csv", full.names=TRUE)
print (rinko_csv_files)
```
 
A quick test to check if the function works
```{r}
test1<- read.csv("~/Documents/GitHub/DNA_monitOki/Environmental parameters/Rinko data python mining/1. Sept17/202009171550_Ｒ２Ｃ-ASTD152-ALC-R02_0264_155041.csv", skip= 44)
colnames(test1) <- vars[c(2, 5, 6:20)]
remove_out<- sapply(test1 [ ,3:17], remove_outliers_column)%>%
  bind_cols()
```

```{r}
path_out <- "~/Documents/GitHub/DNA_monitOki/Environmental parameters/Rinko data clean/"
fileName <- paste(path_out, gsub('.csv', '_processed.csv', f))
write.csv(out_removed_id,fileName)
```

Loop to clean the files: remove the first rows, remove the outliers, etc...
```{r}
for (f in rinko_csv_files) {
  df <- read.csv(f, skip = 44)
  out_removed <- sapply(df [ ,3:17], remove_outliers_column) %>%
   bind_cols()
  out_removed_id <- bind_cols(df[1:2], out_removed)
  colnames(out_removed_id) <- vars[c(2, 5, 6:20)]

  write.csv(out_removed_id, gsub('.csv', '_processed.csv', f))
}
```


```{r}
# path to the separate folder that has the outlier-replaced-with-NA excel files
rinko_outliers_removed <- "~/Documents/GitHub/DNA_monitOki/Environmental parameters/Clean files/"

# list of csv files to loop through and bind together
rinko_csv_no_outliers <- 
  list.files(path = rinko_outliers_removed, recursive = TRUE, pattern = "*.csv")
print(rinko_csv_no_outliers)

readBind <- function (x){
  read.csv(x)
}

#Adding a column with ID information
setwd("~/Documents/GitHub/DNA_monitOki/Environmental parameters/Clean files")
all_outliers_removed <- sapply(rinko_csv_no_outliers, readBind, simplify=FALSE) %>%
  bind_rows(.id = "id") %>% 

#Adding a column with ID information
  mutate(location = substring(str_extract(id, "/..."), 2, 3)) %>%
  relocate(location, .after = date) %>% 
  
  mutate(sample = substring(str_extract(id, "/..."), 2, 4)) %>%
  relocate(sample, .after = location)

# for some reason needs to be a dataframe to write an excel file with row.names = FALSE
write_all_out_removed <- as.data.frame(all_outliers_removed) 
write.xlsx(write_all_out_removed, file = "~/Documents/GitHub/DNA_monitOki/Environmental parameters/rinko_all_outliers_removed.xls", 
           colNames = TRUE, rowNames = FALSE)

View(all_outliers_removed)
nrow(all_outliers_removed)
```

