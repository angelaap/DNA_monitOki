geom_line(aes(y=mean_wind), size=0.5, color="black")+
geom_line(aes(y=mean_maxwind), size=0.5, color="grey")+
scale_y_continuous(name = "Wind intensity (m/s)")+
facet_grid(site_id_en ~ .)+
theme_bw()
windplot
#start with Rinko
rinkototal <- read.csv("~/Documents/GitHub/DNA_monitOki/Environmental parameters/rinko_all_outliers_removed.csv")
sept_rinko<- read.csv("~/Documents/GitHub/DNA_monitOki/Environmental parameters/sept_no_outliers.csv")
#make the number of the columns in both files the same
sept_rinko[1]<- NULL
rinkototal[21]<- NULL
#join both df
rinko_join<- rbind(rinkototal, sept_rinko)
#remove unwanted col
lesscolrinko<- rinko_join[ , -c(1,2,7,18:20)]
set_time<- lesscolrinko %>%
mutate(timenew = lubridate::hms(lesscolrinko$time))
set_time$date <- ymd(set_time$date)
set_time$timenew<- hms(set_time$timenew)
set_time$timenew <- period_to_seconds(set_time$timenew)
#calculate mean/sd
mean_sd_rinko<- set_time %>%
group_by(date, location, sample) %>%
summarise(across(
.cols = is.numeric,
.fns = list(Mean = mean, SD = sd), na.rm = TRUE,
.names = "{col}_{fn}"
))
joinaprox
# Compute the mean of multiple columns
s<-joinaprox %>% group_by(aproxh, sample) %>%
mutate(Salinity_mean = mean(salinity))
View(s)
# Compute the mean of multiple columns
df2 <- joinaprox%>% group_by(aproxh, sample) %>%
summarise(mean_salary=mean(salinity),
mean_bonus= mean(water_temp),
.groups = 'drop') %>%
as.data.frame()
head(df2)
View(df2)
# Compute the mean of multiple columns
df2 <- joinaprox%>% group_by(aproxh, sample) %>%
summarise(mean_salary=mean(salinity),
mean_bonus= mean(water_temp), na.rm = TRUE,
.groups = 'drop') %>%
as.data.frame()
# Compute the mean of multiple columns
df2 <- joinaprox%>% group_by(aproxh, sample) %>%
summarise(mean_salary=mean(salinity),
mean_bonus= mean(water_temp),
.groups = 'drop', na.rm = TRUE) %>%
as.data.frame()
# Compute the mean of multiple columns
df2 <- joinaprox %>% group_by(aproxh, sample) %>%
summarise_if(is.numeric, mean, na.rm = TRUE) %>%
as.data.frame()
# Compute the mean of multiple columns
df2 <- joinaprox %>% group_by(aproxh, sample) %>%
summarise_if(is.numeric, mean, na.rm = TRUE) %>%
as.data.frame()
# Compute the mean of multiple columns
df2 <- joinaprox %>% group_by(aproxh, sample) %>%
)
df2 <- joinaprox %>% group_by(aproxh, sample) %>%
summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)) %>%
as.data.frame()
# Compute the mean of multiple columns
df2 <- joinaprox %>% group_by(aproxh, sample) %>%
# Compute the mean of multiple columns
df2 <- joinaprox %>% group_by(aproxh, sample) %>%
summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE))) %>%
as.data.frame()
df2$sample<- gsub('Ｒ１Ｃ', 'R1C',
gsub('Ｒ１Ｎ', 'R1N',
gsub('Ｒ１Ｓ', 'R1S',
gsub('Ｒ２Ｃ', 'R2C',
gsub('Ｒ２Ｎ', 'R2N',
gsub('Ｒ２Ｓ', 'R2S',
gsub('Ｕ１Ｃ', 'U1C',
gsub('Ｕ１Ｎ', 'U1N',
gsub('Ｕ１Ｓ', 'U1S',
gsub('Ｕ２Ｃ', 'U2C',
gsub('Ｕ２Ｎ', 'U2N',
gsub('Ｕ２Ｓ', 'U2S', df2$sample))))))))))))
View(mean)
View(tidetrial)
View(tide)
tide$Date.time<- as.character(tide$Date.time)
tide$Date.time<- as.character(tide$Date.time)
tide$Date.time<- ymd_hms(tide$Date.time)
#prepare tide data
df2
tide$Date.time<- as.character(tide$Date.time)
date.time<- ymd_hms(tide$Date.time)
date.time
#prepare tide data
df2
tide$Date.time<- as.character(tide$Date.time)
class(tide$Date.time)
date.time<- ymd_h(tide$Date.time)
date.time
View(tide)
tide$Date.time<- as.character(tide$Date.time)
View(tide)
tide <- read.csv("~/Documents/GitHub/DNA_monitOki/Rain, wind, tides/jma_hourly_tidelevel.csv")
tide$Date.time<- as.character(tide$Date.time)
tide$Date.time<- as.character(tide$Date.time)
date.time<- ymd_hms(tide$Date.time)
date.time
tide$Date.time<- as.character(tide$Date.time)
date.time<- ymd_h(tide$Date.time)
date.time
tide$Date.time<- as.character(tide$Date.time)
tide$Date.time<- as.character(tide$Date.time)
tide$Date.time<- ymd_h(tide$Date.time)
tide <- read.csv("~/Documents/GitHub/DNA_monitOki/Rain, wind, tides/jma_hourly_tidelevel.csv")
#tide$Date.time<- as.character(tide$Date.time)
tide$Date.time<- ymd_h(tide$Date.time)
tide <- read.csv("~/Documents/GitHub/DNA_monitOki/Rain, wind, tides/jma_hourly_tidelevel.csv")
#tide$Date.time<- as.character(tide$Date.time)
tide$Date.time<- parse_date_time(tide$Date.time, "ymd")
tide <- read.csv("~/Documents/GitHub/DNA_monitOki/Rain, wind, tides/jma_hourly_tidelevel.csv")
#tide$Date.time<- as.character(tide$Date.time)
trial<- tide$Date.time
trial
parse_date_time(trial, "ymd")
#tide$Date.time<- as.character(tide$Date.time)
trial<- tide$Date.time
parse_date_time(trial, "ymd_h")
#tide$Date.time<- as.character(tide$Date.time)
trial<- tide$Date.time
as.Date(trial)
#tide$Date.time<- as.character(tide$Date.time)
trial<- tide$Date.time
trial$date<- as.Date(trial)
head(trial)
View(trial)
#tide$Date.time<- as.character(tide$Date.time)
trial<- tide
tri<- trial %>%
mutate(across('Date.time', str_replace, '/', '-'))
View(tri)
tri<- trial %>%
mutate(across('Date.time', str_replace, '/', '-'),
mutate(across('Date.time', str_replace, '/', '-')))
#tide$Date.time<- as.character(tide$Date.time)
trial<- tide
tri<- trial %>%
mutate(across('Date.time', str_replace, '/', '-'),
mutate(across('Date.time', str_replace, '/', '-')))
tri<- trial %>%
mutate(across('Date.time', str_replace, '/', '-'),
mutate(across('Date.time', str_replace, '/', '-')))
tri<-parse_date_time(tri$Date.time, "ymd_h")
tri<- trial %>%
mutate(across('Date.time', str_replace, '/', '-'),
mutate(across('Date.time', str_replace, '/', '-')))
tri<-parse_date_time(tri$Date.time, "ymd h")
head(tri)
as<- parse_date_time(tide$Date.time, "%y%m%d")
head(as)
#tide$Date.time<- as.character(tide$Date.time)
trial<- tide
View(trial)
as<- parse_date_time(trial$Date.time, "%y%m%d")
View(as)
as<- parse_date_time(trial$Date.time, "%Y%m%d")
#tide$Date.time<- as.character(tide$Date.time)
trial<- tide
as<- parse_date_time(trial$Date.time, "%Y%M%D")
as<- parse_date_time(trial$Date.time, "%Y%M%d")
head(as)
#tide$Date.time<- as.character(tide$Date.time)
trial<- tide
tri<- trial %>%
mutate(across('Date.time', str_replace, '/', '-'),
mutate(across('Date.time', str_replace, '/', '-')))
tri<-parse_date_time(tri$Date.time, "ymd HM")
View(tri)
tri<-parse_date_time(tri$Date.time, "ymd HM")
#tide$Date.time<- as.character(tide$Date.time)
trial<- tide
tri<- trial %>%
mutate(across('Date.time', str_replace, '/', '-'),
mutate(across('Date.time', str_replace, '/', '-')))
tri$Date.time<-parse_date_time(tri$Date.time, "ymd HM")
tri$Date.time<-parse_date_time(tri$Date.time, "ymd HM")
tri$Date.time<- as.character(tri$Date.time)
head(tri)
tri<- trial %>%
mutate(across('Date.time', str_replace, '/', '-'),
mutate(across('Date.time', str_replace, '/', '-')))
tri$Date.time<-parse_date_time(tri$Date.time, "ymd HM")
View(tri)
tri$Date.time<- as.character(tri$Date.time)
#select each of the places in different df
Goyarain<- new_daterain %>% filter(grepl('Goya', site_id_en))
head(Goyarain)
Kuniyarain<- new_daterain %>% filter(grepl('Kuniya', site_id_en))
Yomitanrain<- new_daterain %>% filter(grepl('Yomitan', site_id_en))
data <- data.frame(x1 = 1:5,    # Create example data
x2 = 6:10,
x3 = 11:15)
data
for(i in 1:ncol(data)) {       # for-loop over columns
data[ , i] <- data[ , i] + 10
}
for(i in 1:ncol(data)) {       # for-loop over columns
data[ , i] <- data[ , i] + 10
}
data
head(Goyarain)
head(df2)
df$aproxh<- Goyarain$dates
df2$aproxh<- Goyarain$dates
df2$aproxh<- df2$dates
Full<- full_join(df2, Goyarain, by c("dates"))
Full<- full_join(df2, Goyarain, by "dates")
Full<- full_join(df2, Goyarain, by dates)
Full<- full_join(df2, Goyarain, by="dates")
Full<- full_join(df2, Goyarain, by=dates)
Full<- left_join(Goyarain, df2, by=dates)
colnames(Goyarain)
colnames(df2)
new_daterain #rain data each 10 min
class(new_daterain$dates)
#select each of the places in different df
Goyarain<- new_daterain %>% filter(grepl('Goya', site_id_en))
Kuniyarain<- new_daterain %>% filter(grepl('Kuniya', site_id_en))
Yomitanrain<- new_daterain %>% filter(grepl('Yomitan', site_id_en))
#on the other hand we have mean that includes rinkodata values.
rinkotimes
class(rinkotimes$totaltime)
aproh<- as.character(rinkotimes$totaltime)
aproxh<- ymd_hms(aproh)
aproxh<- floor_date(aproxh, unit = "hour")
aproxh<- as.character(aproxh)
joinaprox<- cbind(rinkotimes, aproxh)
joinaprox<- joinaprox[ , -c(1, 2, 4)]
#mean value
meanrinko<- joinaprox %>%
group_by(aproxh, sample) %>%
summarise(across(
.cols = is.numeric,
.fns = list(Mean = mean), na.rm = TRUE,
.names = "{col}_{fn}"
))
# Compute the mean of multiple columns
df2 <- joinaprox %>% group_by(aproxh, sample) %>%
summarise(mean_salary=mean(salinity),
mean_bonus= mean(water_temp),
.groups = 'drop', na.rm = TRUE) %>%
as.data.frame()
# Compute the mean of multiple columns
df2 <- joinaprox %>% group_by(aproxh, sample) %>%
summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE))) %>%
as.data.frame()
df2$sample<- gsub('Ｒ１Ｃ', 'R1C',
gsub('Ｒ１Ｎ', 'R1N',
gsub('Ｒ１Ｓ', 'R1S',
gsub('Ｒ２Ｃ', 'R2C',
gsub('Ｒ２Ｎ', 'R2N',
gsub('Ｒ２Ｓ', 'R2S',
gsub('Ｕ１Ｃ', 'U1C',
gsub('Ｕ１Ｎ', 'U1N',
gsub('Ｕ１Ｓ', 'U1S',
gsub('Ｕ２Ｃ', 'U2C',
gsub('Ｕ２Ｎ', 'U2N',
gsub('Ｕ２Ｓ', 'U2S', df2$sample))))))))))))
colnames(df2)
df2$dates<- df2$aproxh
colnames(df2)
View(df2)
Full<- full_join(Goyarain, df2, by=dates)
df = merge(x=df2,y=Goyarain,by="dates",all=TRUE)
View(df)
Head(df)
head(df)
time<- parse_date_time(df$dates, x="Ymd HMS")
df2$aproxh<- df2$dates
df = merge(x=df2,y=Goyarain,by="dates",all=TRUE)
df$time<- parse_date_time(df$dates, x="Ymd HMS")
df$time<- ymd_hms(df$dates)
df$time<- ymd(df$dates)
df$time<- parse_date_time(df$dates, x="ymd hms")
df$time<- parse_date_time(df$dates, x="ymd_hms")
head(Goyarain)
Goyarain$dates<- ymd_hms(Goyarain$dates)
df2$dates<- ymd_hms(df2$dates)
rain<- full_join(df2, Goyarain)
rain<- full_join(df2, Goyarain, by = "dates", keep=TRUE)
View(rain)
date.per.year = structure(c(12110, 12460, 12815, 13196, 13564.5, 13930, 14321,
14652, 15028, 15408, 15792, 16106), .Names = c("2003", "2004",
"2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012",
"2013", "2014"))
date.per.year
df = data.frame(Dates = seq(as.Date("2003/1/1"),
as.Date("2015/1/1"), "days"),
rain = rnorm(length(seq(as.Date("2003/1/1"), as.Date("2015/1/1"), "days"))))
df
a<- c(1,2,3,4,5)
b<- c(0,0,0,0,0)
ab<-cbind(a,b)
print(ab)
a b
data.frame(x=rep(1,10),
+ y=c(0,0,1,0,0,0,0,1,0,0),
data.frame(x=rep(1,10),
y=c(0,0,1,0,0,0,0,1,0,0),
cum_sum_mod=c(1, 2, 1, 2, 3, 1, 2, 1, 2, 3))
tri$date<- tri$Date.time
head(tri$date)
head(tri)
tidefull = merge(x=all,y=tri,by="dates",all=TRUE)
colnames(all)
all$dates<- all$date.x
tidefull = merge(x=all,y=tri,by="dates",all=TRUE)
colnames all
colnames(all)
colnames(tri)
all$date<- all$date.x
tidefull = merge(x=all,y=tri,by="date",all=TRUE)
View(tidefull)
tri$date<- tri$Date.time
all$date<-all$date.x
tidefull = merge(x=all,y=tri,by="date",all=TRUE)
str(tidefull)
corrmatrix<- all[ , -c(1, 2, 3, 4, 15, 21, 27:29)] #leave only numeric col
corrmatrix<- tidefull[ , -c(1, 2, 3, 4, 15, 21, 27:29)] #leave only numeric col
res <- cor(corrmatrix) #get the cor matrix
corrplot(res, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45) # correlation plot
corrmatrix<- tidefull[ , -c(1, 2, 3, 4, 15, 21, 27:29)] #leave only numeric col
res <- cor(corrmatrix) #get the cor matrix
View(res)
corrplot(res, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45) # correlation plot
View(res)
all<- allles[complete.cases(allles), ]
View(all)
complete<- tidefull[complete.cases(tidefull), ]
View(complete)
View(tidefull)
View(tidefull)
View(new_daterain)
#first build the table
Countries<- c("Bangladesh", "China", "India", "Indonesia", "Nigeria", "Pakistan", "Philippines", "South Africa")
IP2018<- c(0, 4, 11, 0, 1, 0, 0, 23)
IP2019<- c(0, 10, 18, 1, 2, 0, 0, 24)
IP2020<- c(1, 5, 12, 0, 5, 0, 0, 28)
Virtual2020<- c(7, 5, 90, 5, 20, 13, 5, 63)
IPHybrid<- c(0, 0, 2, 0, 0, 0, 0, 12)
VirtualHybrid<- c(0, 2, 29, 0, 9, 0, 1, 14)
Tuber_part<- data.frame(Countries, IP2018, IP2019, IP2020, Virtual2020, IPHybrid, VirtualHybrid)
Tuber_IP<- mutate(Tuber_part, IPMean = rowMeans(select(Tuber_part, starts_with("IP2")), na.rm = TRUE))
#remove IP events
tuber_clean<- Tuber_IP[ , -c(2:4)]
tuber_clean<- tuber_clean %>%
mutate_if(is.numeric, round)
#make it long table
long_tub <- tuber_clean %>%
tidyr::gather(event, value, -c(Countries))
long_type <- long_tub %>%
mutate(type = case_when(
startsWith(event, "IP") ~ "In Person",
startsWith(event, "Virtual") ~ "Virtual"
))
#make the plot
tubplot<- ggplot(data = long_type, aes(x = Countries, y = value, fill = event)) +
geom_bar(stat = "identity",  width = 0.7,
position=position_dodge(width = 0.8))+
facet_wrap(~type)+
theme_bw()+
theme(text = element_text(size = 12), axis.text.x = element_text(angle = 45, vjust= 0.5, hjust=1))+
scale_y_continuous(name = "Number of Participants")+
scale_fill_manual(values = c("#570D32", "#D33B44" , "#1d3554", "#42858C"), labels=c("Breckenridge (H/IP22)","Average of 'In Person' events", "eSymposium (V20)", "Breckenridge (H/V22)")) +
labs(fill = "Event name")
tubplot
ggsave("~/Documents/bartub.pdf", device="pdf", width = 10, height = 6)
#first build the table
Countries<- c("Bangladesh", "China", "India", "Indonesia", "Nigeria", "Pakistan", "Philippines", "South Africa")
IP2018<- c(0, 4, 11, 0, 1, 0, 0, 23)
IP2019<- c(0, 10, 18, 1, 2, 0, 0, 24)
IP2020<- c(1, 5, 12, 0, 5, 0, 0, 28)
Virtual2020<- c(7, 5, 90, 4, 20, 13, 5, 63)
IPHybrid<- c(0, 0, 2, 0, 0, 0, 0, 12)
VirtualHybrid<- c(0, 2, 29, 0, 9, 0, 1, 14)
Tuber_part<- data.frame(Countries, IP2018, IP2019, IP2020, Virtual2020, IPHybrid, VirtualHybrid)
Tuber_IP<- mutate(Tuber_part, IPMean = rowMeans(select(Tuber_part, starts_with("IP2")), na.rm = TRUE))
#remove IP events
tuber_clean<- Tuber_IP[ , -c(2:4)]
tuber_clean<- tuber_clean %>%
mutate_if(is.numeric, round)
#make it long table
long_tub <- tuber_clean %>%
tidyr::gather(event, value, -c(Countries))
long_type <- long_tub %>%
mutate(type = case_when(
startsWith(event, "IP") ~ "In Person",
startsWith(event, "Virtual") ~ "Virtual"
))
#make the plot
tubplot<- ggplot(data = long_type, aes(x = Countries, y = value, fill = event)) +
geom_bar(stat = "identity",  width = 0.7,
position=position_dodge(width = 0.8))+
facet_wrap(~type)+
theme_bw()+
theme(text = element_text(size = 12), axis.text.x = element_text(angle = 45, vjust= 0.5, hjust=1))+
scale_y_continuous(name = "Number of Participants")+
scale_fill_manual(values = c("#570D32", "#D33B44" , "#1d3554", "#42858C"), labels=c("Breckenridge (H/IP22)","Average of 'In Person' events", "eSymposium (V20)", "Breckenridge (H/V22)")) +
labs(fill = "Event name")
tubplot
ggsave("~/Documents/bartub.pdf", device="pdf", width = 10, height = 6)
Tuber_part
256-166
333-314
347-335
423- 360
head(IP2019_detail)
IP2019_detail %>%  count(Country == Bangladesh)
View(2019)
#first build the table
Countries<- c("Bangladesh", "China", "India", "Indonesia", "Nigeria", "Pakistan", "Philippines", "South Africa")
IP2018<- c(0, 4, 11, 0, 1, 0, 0, 23)
IP2019<- c(0, 10, 18, 1, 2, 0, 0, 24)
IP2020<- c(1, 5, 12, 0, 5, 0, 0, 28)
Virtual2020<- c(7, 4, 91, 5, 20, 13, 5, 64)
IPHybrid<- c(0, 2, 2, 0, 0, 0, 0, 12)
VirtualHybrid<- c(0, 2, 29, 0, 9, 1, 1, 14)
Tuber_part<- data.frame(Countries, IP2018, IP2019, IP2020, Virtual2020, IPHybrid, VirtualHybrid)
Tuber_part
Tuber_IP<- mutate(Tuber_part, IPMean = rowMeans(select(Tuber_part, starts_with("IP2")), na.rm = TRUE))
#remove IP events
tuber_clean<- Tuber_IP[ , -c(2:4)]
tuber_clean<- tuber_clean %>%
mutate_if(is.numeric, round)
#make it long table
long_tub <- tuber_clean %>%
tidyr::gather(event, value, -c(Countries))
long_type <- long_tub %>%
mutate(type = case_when(
startsWith(event, "IP") ~ "In Person",
startsWith(event, "Virtual") ~ "Virtual"
))
#make the plot
tubplot<- ggplot(data = long_type, aes(x = Countries, y = value, fill = event)) +
geom_bar(stat = "identity",  width = 0.7,
position=position_dodge(width = 0.8))+
facet_wrap(~type)+
theme_bw()+
theme(text = element_text(size = 12), axis.text.x = element_text(angle = 45, vjust= 0.5, hjust=1))+
scale_y_continuous(name = "Number of Participants")+
scale_fill_manual(values = c("#570D32", "#D33B44" , "#1d3554", "#42858C"), labels=c("Breckenridge (H/IP22)","Average of 'In Person' events", "eSymposium (V20)", "Breckenridge (H/V22)")) +
labs(fill = "Event name")
tubplot
ggsave("~/Documents/bartub.pdf", device="pdf", width = 10, height = 6)
#first calculation is done with the Travel footprint calculator by directly input the spreadsheet that Kate prepared in the webpage.
#get the data
IP2018CO2<- read.csv("~/Documents/GitHub/FlightCarbon_Academia22/Results from Didier_Fairmont_2018 mtng_2021-11-24_04_27_01_3c5b.csv")
View(IP2018CO2)
#first calculation is done with the Travel footprint calculator by directly input the spreadsheet that Kate prepared in the webpage.
#get the data
IP2018CO2<- read.csv("~/Documents/GitHub/FlightCarbon_Academia22/Results from Didier_Fairmont_2018 mtng_2021-11-24_04_27_01_3c5b.csv")
IP2019CO2<- read.csv("~/Documents/GitHub/FlightCarbon_Academia22/Results from Didier_Banff_2019 mtng_2021-11-24_03_46_08_8463.csv")
IP2020CO2<- read.csv("~/Documents/GitHub/FlightCarbon_Academia22/Results from Didier_Santa Fe_2020 mtng_2022-01-10_00_35_52_3a44.csv")
H2022CO2<- read.csv("~/Documents/GitHub/FlightCarbon_Academia22/Results from Didier tool_Hybrid flights_2022-09-15_23_29_40_f1cc.csv")
IP2018CO2$event<- c("IP2018")
IP2019CO2$event<- c("IP2019")
IP2020CO2$event<- c("IP2020")
H2022CO2$event<- c("H2022")
FlightTC<- rbind(IP2018CO2, IP2019CO2, IP2020CO2, H2022CO2)
#total emmissions per event
TotalCO2flight<- FlightTC %>%
group_by(event) %>%
summarise(totalco2=sum(co2_kg))
kable(TotalCO2flight, caption="Total kg of CO2e calculated with Travel Footprint calculator")
#calculation of the Co2e emmited per trip
# first remove the rows with "inf" instead of values
histogramprep<- FlightTC %>%
mutate(OneTrip=co2_kg/plane.trips_amount)
clean_total_co2<- histogramprep %>%
filter(!grepl("Inf", OneTrip))
ALlprephisto<- clean_total_co2%>%
group_by(event) %>%
mutate(cumm=cumsum(co2_kg))%>%
arrange(cumm)
#only for IP2020
IP2020_emission <-  ALlprephisto%>%
filter(event == "IP2020")%>%
arrange(OneTrip)%>%
arrange(cumm)
# Value used to transform the data
coeff <- 20000
plot<- ggplot(ALlprephisto, aes(x=co2_kg)) +
geom_bar(aes(y=plane.trips_amount),stat='identity', color="#1d3554", size=1)+
geom_line(aes(y=cumm/coeff), size=0.5, color="#D33B44")+
scale_y_continuous(name = "Plane Trips",sec.axis = sec_axis( trans=~.*coeff, name="Cummulative CO2 emissions (kg)"))+
facet_wrap(~event)+
theme_bw()
#colored in red secondary axis information
plot + theme(axis.text.y.right = element_text(color = "#D33B44"),
axis.ticks.y.right = element_line(color = "#D33B44"),
axis.title.y.right=element_text(color = "#D33B44"))
event<- c("IP2018", "IP2019", "IP2020", "H(IP)22_xxxx" )#check name of the venue
n_participants<- c(325, 374, 290, 289)
air_travel<- c(684.6, 760.9, 557.7, 367)
ground_travel<- c(4.44, 5.36, 0.48, 4.72)
BB<- c(24.37, 28.05, 21.75, 21.77)
IP_emissions <- data.frame(event, n_participants, air_travel, ground_travel, BB)
colnames(IP_emissions)<- c("Event", "N participants", "Air travel", "Ground travel", "B&B")
IP_emissions
